{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "tarea2_GabrielAguilar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "compact-british"
      },
      "source": [
        "# Tarea 2\n",
        "## Gabriel Daniel Aguilar Luna\n",
        "### _Facultad de Ingeniería, Universidad Nacional Autónoma de México_\n",
        "### _Ciudad de México, México_\n",
        "#### gabriel.aguilar@ingenieria.unam.edu\n",
        "***"
      ],
      "id": "compact-british"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8_0KLd7AxM",
        "outputId": "a3e1893c-b4f2-4075-9570-64c2cbb3e43c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "id": "aY8_0KLd7AxM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corporate-startup"
      },
      "source": [
        "#Bibliotecas\n",
        "from nltk.corpus import brown\n",
        "from collections import Counter\n",
        "from random import sample, choice\n",
        "from itertools import chain\n",
        "from copy import deepcopy\n",
        "import cupy as cp\n",
        "from scipy.special import softmax\n",
        "from math import log"
      ],
      "id": "corporate-startup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "connected-device"
      },
      "source": [
        "## Desarollo:\n",
        "\n",
        "A partir del corpus seleccionado en la tarea anterior realizar un modelo del lenguaje neuronal con base en la arquitectura propuesta por Bengio (2003). El corpus ya debe estar preprocesado. S´ıganse los siguientes pasos:"
      ],
      "id": "connected-device"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bridal-coordination",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea03198f-c403-4c18-88e5-e289e84d52f1"
      },
      "source": [
        "brown.sents()"
      ],
      "id": "bridal-coordination",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "musical-print"
      },
      "source": [
        " ## Insertar símbolos de inicio y final de cadena."
      ],
      "id": "musical-print"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "through-slave"
      },
      "source": [
        "# Etiquetas de inicio y final de cadena\n",
        "BOS = '<bos>'\n",
        "EOS = '<eos>'\n",
        "bse = [[BOS]+sent+[EOS] for sent in brown.sents()]"
      ],
      "id": "through-slave",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auburn-gregory"
      },
      "source": [
        "# Esta funcion devuelve una cadena conformada por las palabras en la lista\n",
        "# de strings sent_list. Despues de cada palabra agrega un espacio ' '\n",
        "# para facilitar la visualizacion.\n",
        "# sent_list debe ser una lista de strings.\n",
        "def sentString(sent_list):\n",
        "    return ''.join(w+' ' for w in sent_list)[:-1]"
      ],
      "id": "auburn-gregory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sustained-grain",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cba57d8c-010d-4a04-d021-c078357f2eb3"
      },
      "source": [
        "# Comprobamos que a las sentancias se les han agregado los\n",
        "# simbolos de inicio BOS y final EOS.\n",
        "sentString(sample(bse, 1)[0])"
      ],
      "id": "sustained-grain",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<bos> Actually , however , this turns out to be only part of the picture . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sweet-driving"
      },
      "source": [
        "## Obtener los bigramas que aparecen en el texto (indexar numéricamente)."
      ],
      "id": "sweet-driving"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anticipated-insurance"
      },
      "source": [
        "# tokens es una lista de todas las cadenas de todas las sentencias en el corpus.\n",
        "tokens = [w.lower() for w in chain(*[sent for sent in bse])]\n",
        "# tipos es una lista de todas las palabras diferentes en el corpus\n",
        "tipos = set(tokens)\n",
        "# indice es un diccionario que asigna como valor un numero entero a cada tipo\n",
        "# las cadenas del la lista tipos son las llaves del diccionario.\n",
        "indice = dict(zip(tipos, range(len(tipos))))\n",
        "# Se agrega el simbolo de <oov> para cadenas no vistas en el vocabulario\n",
        "indice['<oov>'] = len(indice)"
      ],
      "id": "anticipated-insurance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adverse-romance",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516ad040-6840-4190-98b0-655c63f0bf25"
      },
      "source": [
        "# Caracteristicas del corpus y del indice de palabras\n",
        "print(\"Tokens:\\t\\t\",len(tokens))\n",
        "print(\"Tipos:\\t\\t\",len(tipos))\n",
        "print(\"Indice:\\t\\t\",len(indice))\n",
        "print(\"Indice[BOS]:\\t\",indice[BOS])\n",
        "print(\"Indice[EOS]:\\t\",indice[EOS])\n",
        "print(\"Indice[OOV]:\\t\",indice['<oov>'])"
      ],
      "id": "adverse-romance",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens:\t\t 1275872\n",
            "Tipos:\t\t 49817\n",
            "Indice:\t\t 49818\n",
            "Indice[BOS]:\t 4734\n",
            "Indice[EOS]:\t 29696\n",
            "Indice[OOV]:\t 49817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "proof-trader"
      },
      "source": [
        "# La variable numSents es una lista de las sentencias del corpus representadas\n",
        "# por los indices numericos de las cadenas que las conforman\n",
        "numSents = deepcopy(bse)\n",
        "for i in range(len(numSents)):\n",
        "    for j in range(len(numSents[i])):\n",
        "        numSents[i][j] = indice[numSents[i][j].lower()]"
      ],
      "id": "proof-trader",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "municipal-arena",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92d29e0-2344-4ea4-f3c3-64d8dc8b14c2"
      },
      "source": [
        "# Se muestra la sentencia más corta:\n",
        "min(numSents, key=len)"
      ],
      "id": "municipal-arena",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4734, 16251, 29696]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absolute-sacrifice"
      },
      "source": [
        "Se crea una lista de bigramas numericos y otra con los bigramas string."
      ],
      "id": "absolute-sacrifice"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "focal-milwaukee"
      },
      "source": [
        "bigramas = list(chain(*[zip(sent,sent[1:]) for sent in numSents]))\n",
        "bigramas_str = list(chain(*[zip(sent,sent[1:]) for sent in bse]))"
      ],
      "id": "focal-milwaukee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "minimal-lawrence",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2932d8-d49b-452e-fb25-e58d531546d2"
      },
      "source": [
        "# Algunos de los bigramas:\n",
        "for muestra in range(50,54):\n",
        "    print(bigramas[muestra],'\\t',bigramas_str[muestra])"
      ],
      "id": "minimal-lawrence",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3547, 6672) \t ('the', 'praise')\n",
            "(6672, 9062) \t ('praise', 'and')\n",
            "(9062, 36092) \t ('and', 'thanks')\n",
            "(36092, 8265) \t ('thanks', 'of')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surgical-elder",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee3883c-1c9d-4ae7-cf03-d7094638f55b"
      },
      "source": [
        "# Total de bigramas:\n",
        "len(bigramas)"
      ],
      "id": "surgical-elder",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1218532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colonial-mozambique"
      },
      "source": [
        "##  Entrenar con los bigramas la red neuronal y obtener los valores para los hiperparámetros. Tomar de 100 unidades para la primera capa oculta (capa lineal) y 300 para la segunda capa oculta (capa con tanh).\n",
        "\n",
        "Variables útiles:"
      ],
      "id": "colonial-mozambique"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chubby-hometown"
      },
      "source": [
        "N = len(indice)\n",
        "d = 100\n",
        "m = 300\n",
        "eta = 0.1\n",
        "iters = 50"
      ],
      "id": "chubby-hometown",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "editorial-carrier"
      },
      "source": [
        "# Esta funcion regresa el vector one hot para el indice dado\n",
        "oneHots_array = cp.identity((N), dtype='uint8')\n",
        "def get_oneHot(indi):\n",
        "    return oneHots_array[indi,:]"
      ],
      "id": "editorial-carrier",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgTfcauKu_gi"
      },
      "source": [
        "Decidí crear una clase llamada red neuronal para trabajar, su función de init, una función para recorrer la red hacía adelante (forward), una función de entrenamiento (train), una de evaluación del modelo (eval) y una última que calcula la probabilidad de una cadena de entrada.\n",
        "\n",
        "Manejé todos los cálculos como multiplicaciones de matrices."
      ],
      "id": "zgTfcauKu_gi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "charitable-element"
      },
      "source": [
        "class red_neuronal:\n",
        "    \n",
        "    #inicializa la red\n",
        "    def __init__(self, N_, d_, m_, eta_=0.1, iters_=100):\n",
        "        self.N = N_\n",
        "        self.d = d_\n",
        "        self.m = m_\n",
        "        self.eta = eta_\n",
        "        self.iters = iters_        \n",
        "        # Array correspondiente a la matriz C\n",
        "        self.C = cp.random.rand(self.d,self.N)\n",
        "        # Array correspondiente a la matriz W\n",
        "        self.W = cp.random.rand(self.m,self.d)\n",
        "        # Array correspondiente a la matriz U\n",
        "        self.U = cp.random.rand(self.N,self.m)\n",
        "    \n",
        "    # Recorre la red hacia adelante\n",
        "    # Retorna un arreglo unidimensional con las probabilidades para cada palabra.\n",
        "    def forward(self,xi):\n",
        "        # C(i) = Cx(i)\n",
        "        self.Ci = cp.dot(self.C,xi)\n",
        "        # h(i) = tanh(WC(i))\n",
        "        self.hi = cp.tanh(cp.dot(self.W,self.Ci))\n",
        "        # a(i) = Uh(i)\n",
        "        self.a = cp.dot(self.U,self.hi)\n",
        "        # softmax(a(i))\n",
        "        return cp.array(softmax(self.a.get()))\n",
        "    \n",
        "    def train(self, bigrams):\n",
        "        # Para cada iteración:\n",
        "        for it in range(self.iters):\n",
        "            # Variable auxiliar\n",
        "            bi_n = 0\n",
        "            # Para cada bigrama:\n",
        "            for bi in bigrams:\n",
        "                # Genera el vector de entrada\n",
        "                xi = get_oneHot(bi[0])\n",
        "                # Obtiene el vector de probabilidades P\n",
        "                p = self.forward(xi)\n",
        "\n",
        "\n",
        "                # Backpropagation\n",
        "\n",
        "                # Al vector de probabilidades en la posicion j le resta 1\n",
        "                p[bi[1]] -= 1\n",
        "                self.d_out = p\n",
        "                # d_h(k) = [1-h(i)^2] U.T d_out\n",
        "                self.d_h = (1 - cp.square(self.hi))*cp.dot(self.U.T, self.d_out)\n",
        "                # d_c = W.T d_h\n",
        "                self.d_c = cp.dot(self.W.T, self.d_h)\n",
        "\n",
        "\n",
        "                # Gradiente descendiente\n",
        "\n",
        "                # U = U - eta d_out h(i)\n",
        "                self.U -= self.eta * cp.dot(self.d_out[cp.newaxis].T, self.hi[cp.newaxis])\n",
        "                # W = W - eta d_h C(i)\n",
        "                self.W -= self.eta * cp.dot(self.d_h[cp.newaxis].T, self.Ci[cp.newaxis])\n",
        "                # C = C - eta d_c x(i)\n",
        "                self.C -= self.eta * cp.dot(self.d_c[cp.newaxis].T, xi[cp.newaxis])\n",
        "                \n",
        "            print('I'+str(it), end=(', ' if (it != iters-1) else '.'))\n",
        "    \n",
        "    def eval(self, bigrams):\n",
        "        H = 0\n",
        "        for bi in bigrams:\n",
        "            xi = get_oneHot(bi[0])\n",
        "            p = self.forward(xi)\n",
        "            H -= log(p[bi[1]])\n",
        "        print('Entropía:',H/len(bigrams), end='\\n\\n')\n",
        "    \n",
        "    def sentProba(self, sentencia):\n",
        "        # Separa la sentencia por espacios\n",
        "        sentencia = sentencia.split(' ')\n",
        "        # Recorre cada token\n",
        "        for w in range(len(sentencia)):\n",
        "            # Si la sentencia se encuentra en el indice se le asigna el valor correspondiente\n",
        "            # de lo contrario se le asigna el valor de <OOV>\n",
        "            sentencia[w] = (indice[sentencia[w]] if (sentencia[w] in indice) else indice['<oov>'])\n",
        "        bis = list(chain(*[zip(sentencia,sentencia[1:])]))\n",
        "        proba = 1\n",
        "        # Obtiene la probabilidad de la cadena\n",
        "        for bi in bis:\n",
        "            proba *= self.forward(get_oneHot(bi[0]))[bi[1]]\n",
        "        return proba"
      ],
      "id": "charitable-element",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "packed-arthritis"
      },
      "source": [
        "red = red_neuronal(N,d,m,eta,iters)"
      ],
      "id": "packed-arthritis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alpha-alarm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c187d1-cf4e-45b5-8021-1d7cdd1dc429"
      },
      "source": [
        "red.train(bigramas[:10000])"
      ],
      "id": "alpha-alarm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0, I1, I2, I3, I4, I5, I6, I7, I8, I9, I10, I11, I12, I13, I14, I15, I16, I17, I18, I19, I20, I21, I22, I23, I24, I25, I26, I27, I28, I29, I30, I31, I32, I33, I34, I35, I36, I37, I38, I39, I40, I41, I42, I43, I44, I45, I46, I47, I48, I49."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-UTLYEntbAB"
      },
      "source": [
        "## Evaluar el modelo con Entropía"
      ],
      "id": "H-UTLYEntbAB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sttm-Sptfys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048944d0-0450-494f-f303-3bd7587854b1"
      },
      "source": [
        "red.eval(bigramas[10000:12000])"
      ],
      "id": "9Sttm-Sptfys",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropía: 30.918138660756377\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Rd2irdohZa"
      },
      "source": [
        "## Calcular la proabilidad de 5 oraciones no vistas en el entrenamiento."
      ],
      "id": "c3Rd2irdohZa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "significant-membership"
      },
      "source": [
        "sent1 = '<BOS> Do not go gentle into that good night . <EOS>' # Dylan Thomas\n",
        "sent2 = '<BOS> I am become death , the destroyer of worlds . <EOS>' # Robert Oppenheimer\n",
        "sent3 = '<BOS> It was the best of times , it was the worst of times . <EOS>' # Charles Dickens\n",
        "sent4 = '<BOS> Anything you can imagine you can make real . <EOS>' # Jules Verne\n",
        "sent5 = '<BOS> Rage , rage against the dying of the light . <EOS>' # Dylan Thomas"
      ],
      "id": "significant-membership",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seasonal-feature",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658db975-30df-41d8-c17b-b6efbb69996f"
      },
      "source": [
        "red.sentProba(sent1)"
      ],
      "id": "seasonal-feature",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(1.25246471e-126)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "velvet-rates",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9238cd6-06d7-4452-acaf-b2ede629f8ee"
      },
      "source": [
        "red.sentProba(sent2)"
      ],
      "id": "velvet-rates",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(4.07852619e-137)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "removed-foundation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055400c1-d542-49c0-c6fb-c5fdcbb502c5"
      },
      "source": [
        "red.sentProba(sent3)"
      ],
      "id": "removed-foundation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(3.70811368e-195)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tested-fever",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6afc5752-9c58-4ea6-b8db-60f76dc5b327"
      },
      "source": [
        "red.sentProba(sent4)"
      ],
      "id": "tested-fever",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(4.2620401e-120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monetary-federal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22421ba8-15e8-4c52-f3cf-18c8e6dbe3a6"
      },
      "source": [
        "red.sentProba(sent5)"
      ],
      "id": "monetary-federal",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(1.92471072e-140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qOe4uPWCkLm"
      },
      "source": [
        "Podemos observar que la sentencia con la probabilidad más alta es la de Verne."
      ],
      "id": "-qOe4uPWCkLm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw1wbUyuC1rn"
      },
      "source": [
        "***\n",
        "\n",
        "## Conclusiones\n",
        "Aguilar Luna Gabriel Daniel:\n",
        "\n",
        "Al realizar esta tarea me encontré con varios obstáculos, en un principio la ejecución tardaba demasiado, lo dejé correr durante unas 5 horas y según mis cálculos le harían falta unas 20 horas para recorrer el 70% de los bigramas generados, por lo que detuve la ejecución y me enfoque en mejorar el código lo más que pude, investigando me enteré de que era posible utilizar una GPU en Google Colaboratory así que cambie la biblioteca de Numpy por Cupy (Aunque al escribir el código me base en las funciones de Numpy) ya que lei que sus funciones esran idénticas por lo que solo hacia falta cambiar de biblioteca. Aún utilizando la GPU los tiempos de ejecución del entrenamiento eran muy largos, por lo que decidí reducir el numero de ejecuciones a 50 y el numero de bigramas para el entrenamiento a 10,000 y el de evaluación a 12,000.\n",
        "\n",
        "Probablemente no estoy realizando el Backpropagation y el Gradiente descendiente de la forma más efectiva. Decidí hacerlo de forma Matricial porque me paracío la forma más clara y sencilla de programarlo.\n",
        "\n",
        "De cualquier forma, aunque no obtuve los mejores resultados está actividad me ha dejado comprender muy bien como funciona, por lo menos en lo general, una red neuronal.\n"
      ],
      "id": "lw1wbUyuC1rn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "formed-latvia"
      },
      "source": [
        "***"
      ],
      "id": "formed-latvia"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pleased-fiction"
      },
      "source": [
        "## Fuentes de Consulta:\n",
        "\n",
        "- [1] Numpy, \"NumPy Reference — NumPy v1.21 Manual\", Numpy.org, 2021. [Online]. Available: https://numpy.org/doc/stable/reference/index.html. [Accessed: 09- Aug- 2021]."
      ],
      "id": "pleased-fiction"
    }
  ]
}