{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compact-british",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "## Gabriel Daniel Aguilar Luna\n",
    "### _Facultad de Ingeniería, Universidad Nacional Autónoma de México_\n",
    "### _Ciudad de México, México_\n",
    "#### gabriel.aguilar@ingenieria.unam.edu\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-device",
   "metadata": {},
   "source": [
    "## Desarollo:\n",
    "\n",
    "A partir del corpus seleccionado en la tarea anterior realizar un modelo del lenguaje neuronal con base en la arquitectura propuesta por Bengio (2003). El corpus ya debe estar preprocesado. S´ıganse los siguientes pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "corporate-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "from nltk.corpus import brown\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample, choice\n",
    "from itertools import chain\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bridal-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-print",
   "metadata": {},
   "source": [
    " ## Insertar símbolos de inicio y final de cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "through-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "bse = [[BOS]+sent+[EOS] for sent in brown.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "auburn-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion devuelve una cadena conformada por las palabras en la lista\n",
    "# de strings sent_list. Despues de cada palabra agrega un espacio ' '\n",
    "# para facilitar la visualizacion.\n",
    "# sent_list debe ser una lista de strings.\n",
    "def sentString(sent_list):\n",
    "    return ''.join(w+' ' for w in sent_list)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sustained-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<BOS> The operations of its other plant in Rochdale and Leesona's former operations in Manchester were transferred to a recently acquired plant in the adjoining town of Heywood . <EOS>\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que a las sentancias se les han agregado los\n",
    "# simbolos de inicio BOS y final EOS.\n",
    "sentString(sample(bse, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-driving",
   "metadata": {},
   "source": [
    "## Obtener los bigramas que aparecen en el texto (indexar numéricamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "anticipated-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens es una lista de todas las cadenas de todas las sentencias en el corpus.\n",
    "tokens = [w for w in chain(*[sent for sent in bse])]\n",
    "# tipos es una lista de todas las palabras diferentes en el corpus\n",
    "tipos = set(tokens)\n",
    "# indice es un diccionario que asigna como valor un numero entero a cada tipo\n",
    "# las cadenas del la lista tipos son las llaves del diccionario.\n",
    "indice = dict(zip(tipos, range(len(tipos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adverse-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\t\t 1275872\n",
      "Tipos:\t\t 56059\n",
      "Indice:\t\t 56059\n",
      "Indice[BOS]:\t 13727\n",
      "Indice[EOS]:\t 25641\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens:\\t\\t\",len(tokens))\n",
    "print(\"Tipos:\\t\\t\",len(tipos))\n",
    "print(\"Indice:\\t\\t\",len(indice))\n",
    "print(\"Indice[BOS]:\\t\",indice[BOS])\n",
    "print(\"Indice[EOS]:\\t\",indice[EOS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proof-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La variable numSents es una lista de las sentencias del corpus representadas\n",
    "# por los indices numericos de las cadenas que las conforman\n",
    "numSents = deepcopy(bse)\n",
    "for i in range(len(numSents)):\n",
    "    for j in range(len(numSents[i])):\n",
    "        numSents[i][j] = indice[numSents[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "municipal-arena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13727, 34720, 25641]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra la sentencia más corta:\n",
    "min(numSents, key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-sacrifice",
   "metadata": {},
   "source": [
    "Se crea una lista de bigramas numericos y otra con los bigramas string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "focal-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramas = list(chain(*[zip(sent,sent[1:]) for sent in numSents]))\n",
    "bigramas_str = list(chain(*[zip(sent,sent[1:]) for sent in bse]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minimal-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19759, 31980) \t ('the', 'praise')\n",
      "(31980, 138) \t ('praise', 'and')\n",
      "(138, 55181) \t ('and', 'thanks')\n",
      "(55181, 27391) \t ('thanks', 'of')\n"
     ]
    }
   ],
   "source": [
    "for muestra in range(50,54):\n",
    "    print(bigramas[muestra],'\\t',bigramas_str[muestra])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-mozambique",
   "metadata": {},
   "source": [
    "##  Entrenar con los bigramas la red neuronal y obtener los valores para los hiperparámetros. Tomar de 100 unidades para la primera capa oculta (capa lineal) y 300 para la segunda capa oculta (capa con tanh).\n",
    "\n",
    "Variables útiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chubby-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(indice)\n",
    "d = 100\n",
    "m = 300\n",
    "eta = 0.1\n",
    "iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dependent-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion regresa el vector one hot para el indice dado\n",
    "def get_oneHot(indi):\n",
    "    return np.identity((N))[indi,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "going-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class red_neuronal:\n",
    "    \n",
    "    def __init__(self, N_, d_, m_, eta_=0.1, iters_=100):\n",
    "        self.N = N_\n",
    "        self.d = d_\n",
    "        self.m = m_\n",
    "        self.eta = eta_\n",
    "        self.iters = iters_        \n",
    "        # Array correspondiente a la matriz C\n",
    "        self.C = np.random.rand(self.d,self.N)\n",
    "        # Array correspondiente a la matriz W\n",
    "        self.W = np.random.rand(self.m,self.d)\n",
    "        # Array correspondiente a la matriz U\n",
    "        self.U = np.random.rand(self.N,self.m)\n",
    "    \n",
    "    def forward(self,xi):\n",
    "        self.Ci = np.dot(self.C,xi)\n",
    "        self.hi = np.tanh(np.dot(self.W,self.Ci))\n",
    "        self.a = np.dot(self.U,self.hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-italian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "formed-latvia",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-fiction",
   "metadata": {},
   "source": [
    "## Fuentes de Consulta:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
